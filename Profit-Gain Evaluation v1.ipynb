{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit-Gain Framework for ML Model Evaluation\n",
    "\n",
    "This is the first attempt to demonstrate the Profit-Gain framework.  Machine-Learning/Deep Learning Model selection and comparison has long relied on measures of accuracy.  However, the accuracy metrics does not allow for a practical cost-benefit analysis to determine the use of one model over another.  The Profit-Gain Framework aims to address this problem through a simple method of evaluation. \n",
    "\n",
    "In the first section, we introduce the framework.  Then we use it to evaluate a few different classifiers in the next section.\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Profit-Gain Framework\n",
    "\n",
    "\n",
    "##### Annual Cost of Meeting Data Processing Quota\n",
    "\n",
    "So say that our quota requirmenet is to process $D$ data-points per second.  As the model takes $T$ seconds to process a single data point, we need $DT$ parallel instances of the model to fulfill this requirement. \n",
    "\n",
    "Each instance of the model takes up $M$ megabytes of memeory and each megabyte costs $d$ dollars on the cloud.  Therefore, the memory required to fulfill our requirement is $MDT$ megabytes in total and the cost of hosting this is $d \\,(MDT)$ per second. \n",
    "\n",
    "From this, we can extrapolate that our annual cost per data-point is $kMT$, where $k$ is some constant that is based on $D$ and $d$.\n",
    "\n",
    "##### Model Revenue\n",
    "\n",
    "So again, we are required to process $D$ data points per second. We make $R$ dollars from each accurate prediction. Our model accuracy is $A$. Therefore, the revenue generated by our model is $ADR$ per second. Note that a perfect model yields a revenue of $DR$ as $A =1$ .  \n",
    "\n",
    "Annual model revenue is thus $jAR$, where $j$ is a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the Baseline\n",
    "\n",
    "Let's assume the baseline model yields no profit. \n",
    "Therefore, annual costs equal revenues.\n",
    "\n",
    "In other words,  $$k MT \\hspace{3mm} \\text{(annual cost)} = j A R \\hspace{3mm} \\text{(annual revenue)}.$$\n",
    "We can reformulate this as as $RA = hMT$ where $h= k\\,/\\,j$.\n",
    "\n",
    "Hence we can solve for $R$\n",
    "$$R = \\frac{hMT}{A}$$\n",
    "\n",
    "which is the revenue generated from a single correctly processed data-point for a basline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing ML Models\n",
    "\n",
    "Assume that we have some fancy new ML Model.  It performs with an accuracy of $A_2$ where $A_2 > A$ and $A$ is the baseline accuracy.\n",
    "\n",
    "The annual revenue of this new model equals \n",
    "\n",
    "$$j A_2 R = j A_2 \\big(\\frac{h MT}{A} \\big) = j h MT (A_2/A) = j (k /j) MT (A_2/A)  =  k MT (A_2/A)$$\n",
    "\n",
    "Furthermore, the model has its own $M_2$ and $T_2$. The annual cost of the model is $kM_2T_2$. \n",
    "\n",
    "Therefore, the model profit equals $kMT(A_2 / A) - kM_2T_2 = k(MT(A_2 / A) - M_2T_2)$. \n",
    "\n",
    "Lets assume $C = MT$ and $C_2 = M_2T_2$. \n",
    "Thus, the profit of this new model equals \n",
    "\n",
    "$$k(C(A_2 / A) - C_2).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximum Profit \n",
    "So recall that $C$ is our baseline cost model. The baseline never drop below $C_2$ ($C_2 \\ge C$). Thus there is a ceiling to our profit! Its one where $A_2 = 1.0$ (we achieve perfect accuracy) and $C_2 = C$ (costs do not go up with the new model). \n",
    "\n",
    "In other words, our maximum possible profit is $kC / A - kC$. \n",
    "Therefore the maximum profit is $kC(1/A - 1)$\n",
    "\n",
    "Percent of maximum profit achieved is\n",
    "\n",
    "$$\\frac{k(C(A_2 / A) - C_2)}{kC(1/A - 1)}= \\frac{C(A_2 / A) - C_2} { C(1/A - 1)} .$$\n",
    "\n",
    "We multiply by $A / A$. This yields\n",
    "\n",
    "$$\\frac{CA_2 - C_2A}{C(1 - A)}.$$\n",
    "\n",
    "At baseline, this metric equals zero. \n",
    "\n",
    "When $CA_2 -C_2 A < 0$, then this metric would be less than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_gain_metric(C_2, A_2):\n",
    "    global A, C\n",
    "    result = C*A_2 - C_2*A\n",
    "    result /= C*(1-A)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the Framework\n",
    "\n",
    "Here we demonstrate the framework using 4 different Classifiers  \n",
    "\n",
    "The 4 classifiers are:\n",
    "* Logistic Regression (Baseline)\n",
    "* Random Forest with 1000 trees \n",
    "* Random Forest with 1000 trees (with Truncated SVD)\n",
    "* BERT \n",
    "\n",
    "##### Loading Dataset \n",
    "Again, we use the 20 News Grops data.   Background information on this dataset can be  [found here](http://qwone.com/~jason/20Newsgroups/). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 11314\n",
      "size of validation set: 7532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "mydata_train = fetch_20newsgroups(subset='train', shuffle=True, \n",
    "                                  remove = ('headers', 'footers', 'quotes'), \n",
    "                                  random_state=42)\n",
    "\n",
    "mydata_test = fetch_20newsgroups(subset='test', shuffle=True,\n",
    "                                 remove = ('headers', 'footers', 'quotes'), \n",
    "                                 random_state=42)\n",
    "\n",
    "print('size of training set: %s' % (len(mydata_train ['data'])))\n",
    "print('size of validation set: %s' % (len(mydata_test['data'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick DataFrame view of this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target\n",
       "0  I was wondering if anyone out there could enli...       7\n",
       "1  A fair number of brave souls who upgraded thei...       4\n",
       "2  well folks, my mac plus finally gave up the gh...       4\n",
       "3  \\nDo you have Weitek's address/phone number?  ...       1\n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mydata_train_df = pd.DataFrame({'data': mydata_train.data, 'target': mydata_train.target})\n",
    "mydata_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establishing the Baseline: Logistic Regression\n",
    "\n",
    "Here we establish our baseline model, a Logistic Regression with a pipeline that incorporates TFIDF and a Truncated SVM in its pipeline.  \n",
    "\n",
    "This model will be used to establish the baseline cost $C=MT$ and basline accuracy $A$.  \n",
    "\n",
    "First we create the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                ('svd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=300,\n",
       "                              n_iter=5, random_state=None, tol=0.0)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used for all classifier pipelines \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# creating the logistic regresion pipeline \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('svd', TruncatedSVD(n_components=300)),\n",
    "        ('clf', LogisticRegression(multi_class='auto', solver='lbfgs'))])\n",
    "\n",
    "# fittingthe data\n",
    "lr_pipeline.fit(mydata_train.data, mydata_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting Baseline Accuracy\n",
    "Now we establish the baseline accuracy $A$ by scoring this classifier on the basline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6165693043016464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = lr_pipeline.score(mydata_test.data, mydata_test.target)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting Baseline Cost\n",
    "\n",
    "Recall again that the cost variable $C$ is a product of $M$ and $T$ where $M$ is the size of the model (in megabytes) and $T$ is the time it takes the model to compute a single data point.  \n",
    "\n",
    "\n",
    "We first measure the runtime of computing preduction on the testing dataset.  Here we use the `timeit` module. \n",
    "\n",
    "Recall that the `n` parameter controls how many executions are done for each timing and it's used to get representative timings and `r` repeat argument controls how many timings are done and its use is to get accurate statistics.  \n",
    "The [documentation](https://docs.python.org/3/library/timeit.html#timeit.Timer.repeat) for `timeit` states the following:\n",
    "\n",
    "> Note: It’s tempting to calculate mean and standard deviation from the result vector and report these. *However, this is not very useful*. In a typical case, the lowest value gives a lower bound for how fast your machine can run the given code snippet; higher values in the result vector are typically not caused by variability in Python’s speed, but by other processes interfering with your timing accuracy. So the min() of the result is probably the only number you should be interested in. \n",
    "\n",
    "Therefore we find the best runtime out of the measurements we use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 s ± 181 ms per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "results = %timeit -r 3 -n 100 -o lr_pipeline.predict(mydata_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.85574203334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the measured minimum runtime to calculate $T$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to skip the timeit part \n",
    "#min_runtime=3.27452979408\n",
    "min_runtime = results.best\n",
    "\n",
    "\n",
    "n_data_pts = len(mydata_test['data'])\n",
    "T = min_runtime / n_data_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use `asizeof` from the `pympler` package, which is the best tool we found to measure the static memory of a given python object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248049.33333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pympler import asizeof\n",
    "M = asizeof.asizeof(lr_pipeline) # in bytes\n",
    "M /= 10*6 # convert to MB\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have our baseline cost, $C$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.11465403725857"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = M*T\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### Profit-Gain Evaluation for a Random Forest Classifier\n",
    "\n",
    "The first classifier we try is a random forest classifier with 1000 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=1000, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', RandomForestClassifier(n_estimators=1000))])\n",
    "\n",
    "rf_pipeline.fit(mydata_train.data, mydata_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we determine the accuracy ($A$) and cost ($C$) for a Random Forest Classifier with 1,000 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6299787573021773"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_rf = rf_pipeline.score(mydata_test.data, mydata_test.target)\n",
    "A_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is slightly higher than our baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.5 s ± 817 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "results = %timeit -r 3 -n 10 -o rf_pipeline.predict(mydata_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining T\n",
    "min_runtime = results.best\n",
    "T_rf = min_runtime / n_data_pts\n",
    "\n",
    "# determining M\n",
    "M_rf = asizeof.asizeof(rf_pipeline) # in bytes\n",
    "M_rf /= 10*6 # convert to MB\n",
    "\n",
    "#calculate Cost for this classifier\n",
    "C_rf = M_rf*T_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just judging by the runtime, the cost of this model is significantly higher than the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708.6065525032902"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.001669933560045"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_gain_metric(C_rf, A_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the profit-gain metric for this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result['Random Forest'] = profit_gain_metric(C_rf, A_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### Profit-Gain Evaluation for a Random Forest Classifier with Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=1000, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline2 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('svd', TruncatedSVD(n_components=300)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=1000))])\n",
    "\n",
    "rf_pipeline2.fit(mydata_train.data, mydata_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5330589484864577"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_rf2 = rf_pipeline2.score(mydata_test.data, mydata_test.target)\n",
    "A_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1 s ± 2.69 s per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "results = %timeit -r 3 -n 10 -o rf_pipeline2.predict(mydata_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330.59489917174403"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining T\n",
    "min_runtime = results.best\n",
    "T_rf2 = min_runtime / n_data_pts\n",
    "\n",
    "# determining M\n",
    "M_rf2 = asizeof.asizeof(rf_pipeline2) # in bytes\n",
    "M_rf2 /= 10*6 # convert to MB\n",
    "\n",
    "#calculate Cost for this classifier\n",
    "C_rf2 = M_rf2*T_rf2\n",
    "C_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.308293489008655"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_gain_metric(C_rf2, A_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Random Forest 2'] = profit_gain_metric(C_rf2, A_rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### Profit-Gain Evaluation for a Random Forest Classifier, 100 trees only\n",
    "\n",
    "\n",
    "Question: the following example is a case where the cost < baseline cost because of runtime. \n",
    "This is probably because it doesn't do Truncated SVD.   This is not allowed under this framework correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline3 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "rf_pipeline3.fit(mydata_train.data, mydata_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5896176314391928"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_rf3 = rf_pipeline3.score(mydata_test.data, mydata_test.target)\n",
    "A_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42 s ± 317 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "results = %timeit -r 3 -n 10 -o rf_pipeline3.predict(mydata_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.96664650886125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining T\n",
    "min_runtime = results.best\n",
    "T_rf3 = min_runtime / n_data_pts\n",
    "\n",
    "# determining M\n",
    "M_rf3 = asizeof.asizeof(rf_pipeline3) # in bytes\n",
    "M_rf3 /= 10*6 # convert to MB\n",
    "\n",
    "#calculate Cost for this classifier\n",
    "C_rf3 = M_rf3*T_rf3\n",
    "\n",
    "C_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1451780996034888"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_gain_metric(C_rf3, A_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Random Forest 3'] = profit_gain_metric(C_rf3, A_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.96664650886125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_rf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### Profit-Gain Evaluation for SVM\n",
    "\n",
    "Here we employ a linear support vector machine (SVM), as done in the sckit-learn tutorial.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                         alpha=1e-3, random_state=42,\n",
    "                         max_iter=5, tol=None))])\n",
    "\n",
    "svm_pipeline.fit(mydata_train.data, mydata_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829527349973447"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_svm = svm_pipeline.score(mydata_test.data, mydata_test.target)\n",
    "A_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.82 s ± 184 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "results = %timeit -r 3 -n 10 -o svm_pipeline.predict(mydata_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.14750826236896"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining T\n",
    "min_runtime = results.best\n",
    "T_svm = min_runtime / n_data_pts\n",
    "\n",
    "# determining M\n",
    "M_svm = asizeof.asizeof(svm_pipeline) # in bytes\n",
    "M_svm /= 10*6 # convert to MB\n",
    "\n",
    "#calculate Cost for this classifier\n",
    "C_svm = M_svm*T_svm\n",
    "\n",
    "C_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.274880276495956"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_gain_metric(C_svm, A_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Logistic Regression Pipeline for future Use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('lr_pipeline.pkl', 'wb')\n",
    "pipeline = pickle.dump(lr_pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lr_pipeline.pkl', 'rb')\n",
    "test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6165693043016464"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.score(mydata_test.data, mydata_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
